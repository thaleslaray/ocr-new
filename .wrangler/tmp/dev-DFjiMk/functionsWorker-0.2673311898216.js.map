{
  "version": 3,
  "sources": ["../../../functions/process.js", "../../../../../../../.wrangler/tmp/pages-nwR3f8/functionsRoutes-0.172162625084042.mjs", "../../../../../../../.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/node_modules/path-to-regexp/src/index.ts", "../../../../../../../.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/pages-template-worker.ts", "../../../../../../../.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../../../../../.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../../../../../../../.wrangler/tmp/bundle-zzZZ55/middleware-insertion-facade.js", "../../../../../../../.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/common.ts", "../../../../../../../.wrangler/tmp/bundle-zzZZ55/middleware-loader.entry.ts", "../../../../../../../.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../../../../../.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../bundle-ZZAt42/middleware-insertion-facade.js", "../../../../../../../.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/common.ts", "../bundle-ZZAt42/middleware-loader.entry.ts"],
  "sourceRoot": "/Users/thaleslaray/code/projetos/hd/cloudflare-ocr-new/.wrangler/tmp/dev-DFjiMk",
  "sourcesContent": ["// Cloudflare Pages Function for OCR processing\nexport async function onRequestPost(context) {\n  const { request, env } = context;\n\n  // CORS headers\n  const corsHeaders = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type, X-API-Key',\n  };\n\n  try {\n    // Get API key from header (client-side) or environment (fallback)\n    const clientApiKey = request.headers.get('X-API-Key');\n    const apiKey = clientApiKey || env.MISTRAL_API_KEY;\n\n    // Debug logging\n    console.log('\uD83D\uDD11 Client API Key present:', !!clientApiKey);\n    console.log('\uD83D\uDD11 Env API Key present:', !!env.MISTRAL_API_KEY);\n    console.log('\uD83D\uDD11 Using API Key:', apiKey ? `${apiKey.substring(0, 10)}...` : 'NONE');\n\n    if (!apiKey) {\n      return new Response(JSON.stringify({\n        error: 'Chave da API Mistral n\u00E3o configurada. Configure no frontend ou use o modo teste.'\n      }), {\n        status: 400,\n        headers: { ...corsHeaders, 'Content-Type': 'application/json' }\n      });\n    }\n\n    // Get the uploaded file and chunk info\n    const formData = await request.formData();\n    const file = formData.get('file');\n    const chunkInfoStr = formData.get('chunk_info');\n\n    let chunkInfo = null;\n    if (chunkInfoStr) {\n      try {\n        chunkInfo = JSON.parse(chunkInfoStr);\n        console.log('\uD83D\uDCE6 Processing chunk:', chunkInfo);\n      } catch (e) {\n        console.warn('Failed to parse chunk info:', e);\n      }\n    }\n\n    if (!file) {\n      return new Response(JSON.stringify({ error: 'Nenhum arquivo enviado' }), {\n        status: 400,\n        headers: { ...corsHeaders, 'Content-Type': 'application/json' }\n      });\n    }\n\n    // No file size limit - we handle chunking intelligently in the frontend\n    // Large files are automatically split into optimal chunks for processing\n\n    const startTime = Date.now();\n\n    // Step 1: Upload file to Mistral\n    console.log('\u2B06\uFE0F Step 1/3: Uploading file to Mistral...');\n    const uploadStart = Date.now();\n\n    const uploadFormData = new FormData();\n    uploadFormData.append('purpose', 'ocr');\n    uploadFormData.append('file', file);\n\n    const uploadResponse = await fetch('https://api.mistral.ai/v1/files', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${apiKey}`\n      },\n      body: uploadFormData\n    });\n\n    if (!uploadResponse.ok) {\n      const errorText = await uploadResponse.text();\n      throw new Error(`Upload failed: ${uploadResponse.status} - ${errorText}`);\n    }\n\n    const uploadResult = await uploadResponse.json();\n    const fileId = uploadResult.id;\n    const uploadTime = Date.now() - uploadStart;\n    console.log(`\u2705 Upload completed in ${uploadTime}ms - File ID: ${fileId}`);\n\n    // Step 2: Get signed URL\n    console.log('\uD83D\uDD17 Step 2/3: Getting signed URL...');\n    const urlStart = Date.now();\n\n    const urlResponse = await fetch(`https://api.mistral.ai/v1/files/${fileId}/url?expiry=24`, {\n      headers: {\n        'Authorization': `Bearer ${apiKey}`,\n        'Accept': 'application/json'\n      }\n    });\n\n    if (!urlResponse.ok) {\n      const errorText = await urlResponse.text();\n      throw new Error(`URL generation failed: ${urlResponse.status} - ${errorText}`);\n    }\n\n    const urlResult = await urlResponse.json();\n    const signedUrl = urlResult.url;\n    const urlTime = Date.now() - urlStart;\n    console.log(`\u2705 URL generated in ${urlTime}ms`);\n\n    // Step 3: Process with OCR (two-phase approach)\n    console.log('\uD83D\uDD0D Step 3/4: Processing with OCR (language detection + image processing)...');\n    const ocrStart = Date.now();\n\n    // Create a simple image annotation schema for Portuguese (default)\n    const createImageAnnotationSchema = (isEnglish = false) => {\n      if (isEnglish) {\n        return {\n          type: \"json_schema\",\n          json_schema: {\n            name: \"ImageAnnotation\",\n            description: \"Detailed image annotation in English\",\n            schema: {\n              type: \"object\",\n              properties: {\n                image_type: {\n                  type: \"string\",\n                  description: \"Type of image in English: chart, table, figure, diagram, photo, schema, flowchart, etc.\"\n                },\n                short_description: {\n                  type: \"string\",\n                  description: \"Short and objective description of the image in English (maximum 100 characters)\"\n                },\n                summary: {\n                  type: \"string\",\n                  description: \"Detailed summary of visual content, data, text and important elements of the image in English\"\n                }\n              },\n              required: [\"image_type\", \"short_description\", \"summary\"],\n              additionalProperties: false\n            },\n            strict: false\n          }\n        };\n      } else {\n        return {\n          type: \"json_schema\",\n          json_schema: {\n            name: \"ImageAnnotation\",\n            description: \"Anota\u00E7\u00E3o detalhada de imagem em portugu\u00EAs brasileiro\",\n            schema: {\n              type: \"object\",\n              properties: {\n                image_type: {\n                  type: \"string\",\n                  description: \"Tipo da imagem em portugu\u00EAs: gr\u00E1fico, tabela, figura, diagrama, foto, esquema, fluxograma, etc.\"\n                },\n                short_description: {\n                  type: \"string\",\n                  description: \"Descri\u00E7\u00E3o curta e objetiva da imagem em portugu\u00EAs (m\u00E1ximo 100 caracteres)\"\n                },\n                summary: {\n                  type: \"string\",\n                  description: \"Resumo detalhado do conte\u00FAdo visual, dados, texto e elementos importantes da imagem em portugu\u00EAs\"\n                }\n              },\n              required: [\"image_type\", \"short_description\", \"summary\"],\n              additionalProperties: false\n            },\n            strict: false\n          }\n        };\n      }\n    };\n\n    // Step 3a: First OCR call to detect language (text only, faster)\n    console.log('\uD83D\uDD0D Step 3a/4: Quick language detection...');\n    const languageDetectionRequest = {\n      model: 'mistral-ocr-latest',\n      document: {\n        type: 'document_url',\n        document_url: signedUrl\n      },\n      include_image_base64: false // Skip images for language detection\n    };\n\n    const languageResponse = await fetch('https://api.mistral.ai/v1/ocr', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${apiKey}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify(languageDetectionRequest)\n    });\n\n    if (!languageResponse.ok) {\n      const errorText = await languageResponse.text();\n      throw new Error(`Language detection failed: ${languageResponse.status} - ${errorText}`);\n    }\n\n    const languageResult = await languageResponse.json();\n\n    // Detect language from first page text\n    const firstPageText = (languageResult.pages?.[0]?.markdown || '').toLowerCase();\n    const englishMarkers = (firstPageText.match(/\\b(the|and|you|your|are|have|that|this|with|from|they|been|were|there|their|would|which)\\b/g) || []).length;\n    const portugueseMarkers = (firstPageText.match(/\\b(que|com|uma|dos|das|por|para|s\u00E3o|est\u00E1|foram|t\u00EAm|ser\u00E1|pode|deve|ter|ser|fazer|mais|muito|como|quando|onde)\\b/g) || []).length;\n\n    const minThreshold = 3;\n    const isEnglish = englishMarkers > minThreshold && englishMarkers > portugueseMarkers * 1.5;\n\n    console.log(`Language markers - EN: ${englishMarkers}, PT: ${portugueseMarkers}`);\n    console.log(`Detected language: ${isEnglish ? 'English' : 'Portuguese'}`);\n\n    // Step 3b: Second OCR call with correct schema for images\n    console.log('\uD83D\uDD0D Step 3b/4: Processing with images and correct language schema...');\n    const ocrRequestBody = {\n      model: 'mistral-ocr-latest',\n      document: {\n        type: 'document_url',\n        document_url: signedUrl\n      },\n      include_image_base64: true,\n      bbox_annotation_format: createImageAnnotationSchema(isEnglish)\n    };\n\n    // Note: Mistral OCR API doesn't support page_range parameter\n    // We'll process the whole file and let the chunking happen at file level\n    if (chunkInfo && chunkInfo.isChunked) {\n      console.log(`\uD83D\uDCC4 Processing chunk ${chunkInfo.chunkNumber}/${chunkInfo.totalChunks} (simulated range: pages ${chunkInfo.startPage}-${chunkInfo.endPage})`);\n    }\n\n    const ocrResponse = await fetch('https://api.mistral.ai/v1/ocr', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${apiKey}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify(ocrRequestBody)\n    });\n\n    if (!ocrResponse.ok) {\n      const errorText = await ocrResponse.text();\n      throw new Error(`OCR processing failed: ${ocrResponse.status} - ${errorText}`);\n    }\n\n    const ocrResult = await ocrResponse.json();\n    const ocrTime = Date.now() - ocrStart;\n    const totalTime = Date.now() - startTime;\n\n    console.log(`\u2705 OCR completed in ${ocrTime}ms`);\n    console.log(`\uD83C\uDF89 Total processing time: ${totalTime}ms`);\n    console.log('\uD83D\uDCCB OCR Result from Mistral:', JSON.stringify(ocrResult, null, 2));\n\n    // Extract content from Mistral response - it comes in pages array\n    let markdownContent = '';\n    if (ocrResult.pages && ocrResult.pages.length > 0) {\n      // Use previously detected language\n      let pageLabel, visualContentHeader, detectedLang;\n\n      if (isEnglish) {\n        pageLabel = 'PAGE';\n        visualContentHeader = 'VISUAL CONTENT IDENTIFIED:';\n        detectedLang = 'English';\n      } else {\n        pageLabel = 'P\u00C1GINA';\n        visualContentHeader = 'CONTE\u00DADO VISUAL IDENTIFICADO:';\n        detectedLang = 'Portuguese';\n      }\n\n      // Process each page following academic markdown standards\n      markdownContent = ocrResult.pages.map((page, index) => {\n        const pageNumber = index + 1;\n\n        // Page separator following academic standards\n        let pageContent = '';\n        if (index > 0) {\n          // Add page break divider between pages (academic standard)\n          pageContent += '\\n\\n---\\n\\n';\n        }\n\n        // Page header as H2 (section level) following academic hierarchy\n        pageContent += `## \uD83D\uDCC4 ${pageLabel} ${pageNumber}\\n\\n`;\n\n        // Add the actual page content with proper spacing\n        let content = page.markdown || '';\n\n        // Remove useless image references that LLMs can't see\n        content = content.replace(/!\\[img-\\d+\\.(jpeg|jpg|png|gif|webp)\\]\\(img-\\d+\\.(jpeg|jpg|png|gif|webp)\\)/g, '');\n\n        pageContent += content;\n\n        // Add image descriptions following academic formatting\n        if (page.images && page.images.length > 0) {\n          const imageDescriptions = page.images\n            .filter(img => img.image_annotation)\n            .map(img => {\n              try {\n                const annotation = typeof img.image_annotation === 'string'\n                  ? JSON.parse(img.image_annotation)\n                  : img.image_annotation;\n\n                // Format image descriptions as academic block quotes\n                return `> **${annotation.image_type.toUpperCase()}:** ${annotation.short_description}\\n>\\n> ${annotation.summary}`;\n              } catch (e) {\n                console.log('Erro ao processar anota\u00E7\u00E3o da imagem:', e);\n                return `> **IMAGE:** ${img.image_annotation}`;\n              }\n            });\n\n          if (imageDescriptions.length > 0) {\n            // Add visual content section following academic standards\n            pageContent += `\\n\\n### ${visualContentHeader}\\n\\n` + imageDescriptions.join('\\n\\n');\n          }\n        }\n\n        return pageContent;\n      }).join('\\n\\n');\n\n      console.log(`\uD83D\uDCC4 Extracted ${ocrResult.pages.length} pages of content`);\n    } else {\n      // Fallback to other possible fields\n      markdownContent = ocrResult.content || ocrResult.text || ocrResult.markdown || JSON.stringify(ocrResult, null, 2);\n    }\n\n    const response = {\n      success: true,\n      markdown: markdownContent,\n      filename: file.name,\n      isReal: true,\n      timing: {\n        upload: uploadTime,\n        url: urlTime,\n        ocr: ocrTime,\n        total: totalTime\n      },\n      stats: {\n        pages: ocrResult.pages?.length || 0,\n        fileSize: file.size,\n        usage: ocrResult.usage_info\n      }\n    };\n\n    // Add chunk information if this was a chunked request\n    if (chunkInfo) {\n      response.chunkInfo = chunkInfo;\n      response.isChunked = true;\n    }\n\n    return new Response(JSON.stringify(response), {\n      headers: { ...corsHeaders, 'Content-Type': 'application/json' }\n    });\n\n  } catch (error) {\n    console.error('Processing error:', error);\n    return new Response(JSON.stringify({\n      success: false,\n      error: `Erro no processamento: ${error.message}`\n    }), {\n      status: 500,\n      headers: { ...corsHeaders, 'Content-Type': 'application/json' }\n    });\n  }\n}\n\n// Handle OPTIONS request for CORS\nexport async function onRequestOptions() {\n  return new Response(null, {\n    headers: {\n      'Access-Control-Allow-Origin': '*',\n      'Access-Control-Allow-Methods': 'POST, OPTIONS',\n      'Access-Control-Allow-Headers': 'Content-Type, X-API-Key',\n    }\n  });\n}", "import { onRequestOptions as __process_js_onRequestOptions } from \"/Users/thaleslaray/code/projetos/hd/cloudflare-ocr-new/functions/process.js\"\nimport { onRequestPost as __process_js_onRequestPost } from \"/Users/thaleslaray/code/projetos/hd/cloudflare-ocr-new/functions/process.js\"\n\nexport const routes = [\n    {\n      routePath: \"/process\",\n      mountPath: \"/\",\n      method: \"OPTIONS\",\n      middlewares: [],\n      modules: [__process_js_onRequestOptions],\n    },\n  {\n      routePath: \"/process\",\n      mountPath: \"/\",\n      method: \"POST\",\n      middlewares: [],\n      modules: [__process_js_onRequestPost],\n    },\n  ]", "/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type:\n    | \"OPEN\"\n    | \"CLOSE\"\n    | \"PATTERN\"\n    | \"NAME\"\n    | \"CHAR\"\n    | \"ESCAPED_CHAR\"\n    | \"MODIFIER\"\n    | \"END\";\n  index: number;\n  value: string;\n}\n\n/**\n * Tokenize input string.\n */\nfunction lexer(str: string): LexToken[] {\n  const tokens: LexToken[] = [];\n  let i = 0;\n\n  while (i < str.length) {\n    const char = str[i];\n\n    if (char === \"*\" || char === \"+\" || char === \"?\") {\n      tokens.push({ type: \"MODIFIER\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"\\\\\") {\n      tokens.push({ type: \"ESCAPED_CHAR\", index: i++, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"{\") {\n      tokens.push({ type: \"OPEN\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"}\") {\n      tokens.push({ type: \"CLOSE\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \":\") {\n      let name = \"\";\n      let j = i + 1;\n\n      while (j < str.length) {\n        const code = str.charCodeAt(j);\n\n        if (\n          // `0-9`\n          (code >= 48 && code <= 57) ||\n          // `A-Z`\n          (code >= 65 && code <= 90) ||\n          // `a-z`\n          (code >= 97 && code <= 122) ||\n          // `_`\n          code === 95\n        ) {\n          name += str[j++];\n          continue;\n        }\n\n        break;\n      }\n\n      if (!name) throw new TypeError(`Missing parameter name at ${i}`);\n\n      tokens.push({ type: \"NAME\", index: i, value: name });\n      i = j;\n      continue;\n    }\n\n    if (char === \"(\") {\n      let count = 1;\n      let pattern = \"\";\n      let j = i + 1;\n\n      if (str[j] === \"?\") {\n        throw new TypeError(`Pattern cannot start with \"?\" at ${j}`);\n      }\n\n      while (j < str.length) {\n        if (str[j] === \"\\\\\") {\n          pattern += str[j++] + str[j++];\n          continue;\n        }\n\n        if (str[j] === \")\") {\n          count--;\n          if (count === 0) {\n            j++;\n            break;\n          }\n        } else if (str[j] === \"(\") {\n          count++;\n          if (str[j + 1] !== \"?\") {\n            throw new TypeError(`Capturing groups are not allowed at ${j}`);\n          }\n        }\n\n        pattern += str[j++];\n      }\n\n      if (count) throw new TypeError(`Unbalanced pattern at ${i}`);\n      if (!pattern) throw new TypeError(`Missing pattern at ${i}`);\n\n      tokens.push({ type: \"PATTERN\", index: i, value: pattern });\n      i = j;\n      continue;\n    }\n\n    tokens.push({ type: \"CHAR\", index: i, value: str[i++] });\n  }\n\n  tokens.push({ type: \"END\", index: i, value: \"\" });\n\n  return tokens;\n}\n\nexport interface ParseOptions {\n  /**\n   * Set the default delimiter for repeat parameters. (default: `'/'`)\n   */\n  delimiter?: string;\n  /**\n   * List of characters to automatically consider prefixes when parsing.\n   */\n  prefixes?: string;\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): Token[] {\n  const tokens = lexer(str);\n  const { prefixes = \"./\", delimiter = \"/#?\" } = options;\n  const result: Token[] = [];\n  let key = 0;\n  let i = 0;\n  let path = \"\";\n\n  const tryConsume = (type: LexToken[\"type\"]): string | undefined => {\n    if (i < tokens.length && tokens[i].type === type) return tokens[i++].value;\n  };\n\n  const mustConsume = (type: LexToken[\"type\"]): string => {\n    const value = tryConsume(type);\n    if (value !== undefined) return value;\n    const { type: nextType, index } = tokens[i];\n    throw new TypeError(`Unexpected ${nextType} at ${index}, expected ${type}`);\n  };\n\n  const consumeText = (): string => {\n    let result = \"\";\n    let value: string | undefined;\n    while ((value = tryConsume(\"CHAR\") || tryConsume(\"ESCAPED_CHAR\"))) {\n      result += value;\n    }\n    return result;\n  };\n\n  const isSafe = (value: string): boolean => {\n    for (const char of delimiter) if (value.indexOf(char) > -1) return true;\n    return false;\n  };\n\n  const safePattern = (prefix: string) => {\n    const prev = result[result.length - 1];\n    const prevText = prefix || (prev && typeof prev === \"string\" ? prev : \"\");\n\n    if (prev && !prevText) {\n      throw new TypeError(\n        `Must have text between two parameters, missing text after \"${(prev as Key).name}\"`,\n      );\n    }\n\n    if (!prevText || isSafe(prevText)) return `[^${escapeString(delimiter)}]+?`;\n    return `(?:(?!${escapeString(prevText)})[^${escapeString(delimiter)}])+?`;\n  };\n\n  while (i < tokens.length) {\n    const char = tryConsume(\"CHAR\");\n    const name = tryConsume(\"NAME\");\n    const pattern = tryConsume(\"PATTERN\");\n\n    if (name || pattern) {\n      let prefix = char || \"\";\n\n      if (prefixes.indexOf(prefix) === -1) {\n        path += prefix;\n        prefix = \"\";\n      }\n\n      if (path) {\n        result.push(path);\n        path = \"\";\n      }\n\n      result.push({\n        name: name || key++,\n        prefix,\n        suffix: \"\",\n        pattern: pattern || safePattern(prefix),\n        modifier: tryConsume(\"MODIFIER\") || \"\",\n      });\n      continue;\n    }\n\n    const value = char || tryConsume(\"ESCAPED_CHAR\");\n    if (value) {\n      path += value;\n      continue;\n    }\n\n    if (path) {\n      result.push(path);\n      path = \"\";\n    }\n\n    const open = tryConsume(\"OPEN\");\n    if (open) {\n      const prefix = consumeText();\n      const name = tryConsume(\"NAME\") || \"\";\n      const pattern = tryConsume(\"PATTERN\") || \"\";\n      const suffix = consumeText();\n\n      mustConsume(\"CLOSE\");\n\n      result.push({\n        name: name || (pattern ? key++ : \"\"),\n        pattern: name && !pattern ? safePattern(prefix) : pattern,\n        prefix,\n        suffix,\n        modifier: tryConsume(\"MODIFIER\") || \"\",\n      });\n      continue;\n    }\n\n    mustConsume(\"END\");\n  }\n\n  return result;\n}\n\nexport interface TokensToFunctionOptions {\n  /**\n   * When `true` the regexp will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * Function for encoding input strings for output.\n   */\n  encode?: (value: string, token: Key) => string;\n  /**\n   * When `false` the function can produce an invalid (unmatched) path. (default: `true`)\n   */\n  validate?: boolean;\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends object = object>(\n  str: string,\n  options?: ParseOptions & TokensToFunctionOptions,\n) {\n  return tokensToFunction<P>(parse(str, options), options);\n}\n\nexport type PathFunction<P extends object = object> = (data?: P) => string;\n\n/**\n * Expose a method for transforming tokens into the path function.\n */\nexport function tokensToFunction<P extends object = object>(\n  tokens: Token[],\n  options: TokensToFunctionOptions = {},\n): PathFunction<P> {\n  const reFlags = flags(options);\n  const { encode = (x: string) => x, validate = true } = options;\n\n  // Compile all the tokens into regexps.\n  const matches = tokens.map((token) => {\n    if (typeof token === \"object\") {\n      return new RegExp(`^(?:${token.pattern})$`, reFlags);\n    }\n  });\n\n  return (data: Record<string, any> | null | undefined) => {\n    let path = \"\";\n\n    for (let i = 0; i < tokens.length; i++) {\n      const token = tokens[i];\n\n      if (typeof token === \"string\") {\n        path += token;\n        continue;\n      }\n\n      const value = data ? data[token.name] : undefined;\n      const optional = token.modifier === \"?\" || token.modifier === \"*\";\n      const repeat = token.modifier === \"*\" || token.modifier === \"+\";\n\n      if (Array.isArray(value)) {\n        if (!repeat) {\n          throw new TypeError(\n            `Expected \"${token.name}\" to not repeat, but got an array`,\n          );\n        }\n\n        if (value.length === 0) {\n          if (optional) continue;\n\n          throw new TypeError(`Expected \"${token.name}\" to not be empty`);\n        }\n\n        for (let j = 0; j < value.length; j++) {\n          const segment = encode(value[j], token);\n\n          if (validate && !(matches[i] as RegExp).test(segment)) {\n            throw new TypeError(\n              `Expected all \"${token.name}\" to match \"${token.pattern}\", but got \"${segment}\"`,\n            );\n          }\n\n          path += token.prefix + segment + token.suffix;\n        }\n\n        continue;\n      }\n\n      if (typeof value === \"string\" || typeof value === \"number\") {\n        const segment = encode(String(value), token);\n\n        if (validate && !(matches[i] as RegExp).test(segment)) {\n          throw new TypeError(\n            `Expected \"${token.name}\" to match \"${token.pattern}\", but got \"${segment}\"`,\n          );\n        }\n\n        path += token.prefix + segment + token.suffix;\n        continue;\n      }\n\n      if (optional) continue;\n\n      const typeOfMessage = repeat ? \"an array\" : \"a string\";\n      throw new TypeError(`Expected \"${token.name}\" to be ${typeOfMessage}`);\n    }\n\n    return path;\n  };\n}\n\nexport interface RegexpToFunctionOptions {\n  /**\n   * Function for decoding strings for params.\n   */\n  decode?: (value: string, token: Key) => string;\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends object = object> {\n  path: string;\n  index: number;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends object = object> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends object = object> = (\n  path: string,\n) => Match<P>;\n\n/**\n * Create path match function from `path-to-regexp` spec.\n */\nexport function match<P extends object = object>(\n  str: Path,\n  options?: ParseOptions & TokensToRegexpOptions & RegexpToFunctionOptions,\n) {\n  const keys: Key[] = [];\n  const re = pathToRegexp(str, keys, options);\n  return regexpToFunction<P>(re, keys, options);\n}\n\n/**\n * Create a path match function from `path-to-regexp` output.\n */\nexport function regexpToFunction<P extends object = object>(\n  re: RegExp,\n  keys: Key[],\n  options: RegexpToFunctionOptions = {},\n): MatchFunction<P> {\n  const { decode = (x: string) => x } = options;\n\n  return function (pathname: string) {\n    const m = re.exec(pathname);\n    if (!m) return false;\n\n    const { 0: path, index } = m;\n    const params = Object.create(null);\n\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n\n      const key = keys[i - 1];\n\n      if (key.modifier === \"*\" || key.modifier === \"+\") {\n        params[key.name] = m[i].split(key.prefix + key.suffix).map((value) => {\n          return decode(value, key);\n        });\n      } else {\n        params[key.name] = decode(m[i], key);\n      }\n    }\n\n    return { path, index, params };\n  };\n}\n\n/**\n * Escape a regular expression string.\n */\nfunction escapeString(str: string) {\n  return str.replace(/([.+*?=^!:${}()[\\]|/\\\\])/g, \"\\\\$1\");\n}\n\n/**\n * Get the flags for a regexp from the options.\n */\nfunction flags(options?: { sensitive?: boolean }) {\n  return options && options.sensitive ? \"\" : \"i\";\n}\n\n/**\n * Metadata about a key.\n */\nexport interface Key {\n  name: string | number;\n  prefix: string;\n  suffix: string;\n  pattern: string;\n  modifier: string;\n}\n\n/**\n * A token is a string (nothing special) or key metadata (capture group).\n */\nexport type Token = string | Key;\n\n/**\n * Pull out keys from a regexp.\n */\nfunction regexpToRegexp(path: RegExp, keys?: Key[]): RegExp {\n  if (!keys) return path;\n\n  const groupsRegex = /\\((?:\\?<(.*?)>)?(?!\\?)/g;\n\n  let index = 0;\n  let execResult = groupsRegex.exec(path.source);\n  while (execResult) {\n    keys.push({\n      // Use parenthesized substring match if available, index otherwise\n      name: execResult[1] || index++,\n      prefix: \"\",\n      suffix: \"\",\n      modifier: \"\",\n      pattern: \"\",\n    });\n    execResult = groupsRegex.exec(path.source);\n  }\n\n  return path;\n}\n\n/**\n * Transform an array into a regexp.\n */\nfunction arrayToRegexp(\n  paths: Array<string | RegExp>,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n): RegExp {\n  const parts = paths.map((path) => pathToRegexp(path, keys, options).source);\n  return new RegExp(`(?:${parts.join(\"|\")})`, flags(options));\n}\n\n/**\n * Create a path regexp from string input.\n */\nfunction stringToRegexp(\n  path: string,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n) {\n  return tokensToRegexp(parse(path, options), keys, options);\n}\n\nexport interface TokensToRegexpOptions {\n  /**\n   * When `true` the regexp will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * When `true` the regexp won't allow an optional trailing delimiter to match. (default: `false`)\n   */\n  strict?: boolean;\n  /**\n   * When `true` the regexp will match to the end of the string. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * When `true` the regexp will match from the beginning of the string. (default: `true`)\n   */\n  start?: boolean;\n  /**\n   * Sets the final character for non-ending optimistic matches. (default: `/`)\n   */\n  delimiter?: string;\n  /**\n   * List of characters that can also be \"end\" characters.\n   */\n  endsWith?: string;\n  /**\n   * Encode path tokens for use in the `RegExp`.\n   */\n  encode?: (value: string) => string;\n}\n\n/**\n * Expose a function for taking tokens and returning a RegExp.\n */\nexport function tokensToRegexp(\n  tokens: Token[],\n  keys?: Key[],\n  options: TokensToRegexpOptions = {},\n) {\n  const {\n    strict = false,\n    start = true,\n    end = true,\n    encode = (x: string) => x,\n    delimiter = \"/#?\",\n    endsWith = \"\",\n  } = options;\n  const endsWithRe = `[${escapeString(endsWith)}]|$`;\n  const delimiterRe = `[${escapeString(delimiter)}]`;\n  let route = start ? \"^\" : \"\";\n\n  // Iterate over the tokens and create our regexp string.\n  for (const token of tokens) {\n    if (typeof token === \"string\") {\n      route += escapeString(encode(token));\n    } else {\n      const prefix = escapeString(encode(token.prefix));\n      const suffix = escapeString(encode(token.suffix));\n\n      if (token.pattern) {\n        if (keys) keys.push(token);\n\n        if (prefix || suffix) {\n          if (token.modifier === \"+\" || token.modifier === \"*\") {\n            const mod = token.modifier === \"*\" ? \"?\" : \"\";\n            route += `(?:${prefix}((?:${token.pattern})(?:${suffix}${prefix}(?:${token.pattern}))*)${suffix})${mod}`;\n          } else {\n            route += `(?:${prefix}(${token.pattern})${suffix})${token.modifier}`;\n          }\n        } else {\n          if (token.modifier === \"+\" || token.modifier === \"*\") {\n            throw new TypeError(\n              `Can not repeat \"${token.name}\" without a prefix and suffix`,\n            );\n          }\n\n          route += `(${token.pattern})${token.modifier}`;\n        }\n      } else {\n        route += `(?:${prefix}${suffix})${token.modifier}`;\n      }\n    }\n  }\n\n  if (end) {\n    if (!strict) route += `${delimiterRe}?`;\n\n    route += !options.endsWith ? \"$\" : `(?=${endsWithRe})`;\n  } else {\n    const endToken = tokens[tokens.length - 1];\n    const isEndDelimited =\n      typeof endToken === \"string\"\n        ? delimiterRe.indexOf(endToken[endToken.length - 1]) > -1\n        : endToken === undefined;\n\n    if (!strict) {\n      route += `(?:${delimiterRe}(?=${endsWithRe}))?`;\n    }\n\n    if (!isEndDelimited) {\n      route += `(?=${delimiterRe}|${endsWithRe})`;\n    }\n  }\n\n  return new RegExp(route, flags(options));\n}\n\n/**\n * Supported `path-to-regexp` input types.\n */\nexport type Path = string | RegExp | Array<string | RegExp>;\n\n/**\n * Normalize the given path string, returning a regular expression.\n *\n * An empty array can be passed in for the keys, which will hold the\n * placeholder key descriptions. For example, using `/user/:id`, `keys` will\n * contain `[{ name: 'id', delimiter: '/', optional: false, repeat: false }]`.\n */\nexport function pathToRegexp(\n  path: Path,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n) {\n  if (path instanceof RegExp) return regexpToRegexp(path, keys);\n  if (Array.isArray(path)) return arrayToRegexp(path, keys, options);\n  return stringToRegexp(path, keys, options);\n}\n", "import { match } from \"path-to-regexp\";\n\n//note: this explicitly does not include the * character, as pages requires this\nconst escapeRegex = /[.+?^${}()|[\\]\\\\]/g;\n\ntype HTTPMethod =\n\t| \"HEAD\"\n\t| \"OPTIONS\"\n\t| \"GET\"\n\t| \"POST\"\n\t| \"PUT\"\n\t| \"PATCH\"\n\t| \"DELETE\";\n\n/* TODO: Grab these from @cloudflare/workers-types instead */\ntype Params<P extends string = string> = Record<P, string | string[]>;\n\ntype EventContext<Env, P extends string, Data> = {\n\trequest: Request;\n\tfunctionPath: string;\n\twaitUntil: (promise: Promise<unknown>) => void;\n\tpassThroughOnException: () => void;\n\tnext: (input?: Request | string, init?: RequestInit) => Promise<Response>;\n\tenv: Env & { ASSETS: { fetch: typeof fetch } };\n\tparams: Params<P>;\n\tdata: Data;\n};\n\ndeclare type PagesFunction<\n\tEnv = unknown,\n\tP extends string = string,\n\tData extends Record<string, unknown> = Record<string, unknown>,\n> = (context: EventContext<Env, P, Data>) => Response | Promise<Response>;\n/* end @cloudflare/workers-types */\n\ntype RouteHandler = {\n\troutePath: string;\n\tmountPath: string;\n\tmethod?: HTTPMethod;\n\tmodules: PagesFunction[];\n\tmiddlewares: PagesFunction[];\n};\n\n// inject `routes` via ESBuild\ndeclare const routes: RouteHandler[];\n// define `__FALLBACK_SERVICE__` via ESBuild\ndeclare const __FALLBACK_SERVICE__: string;\n\n// expect an ASSETS fetcher binding pointing to the asset-server stage\ntype FetchEnv = {\n\t[name: string]: { fetch: typeof fetch };\n\tASSETS: { fetch: typeof fetch };\n};\n\ntype WorkerContext = {\n\twaitUntil: (promise: Promise<unknown>) => void;\n\tpassThroughOnException: () => void;\n};\n\nfunction* executeRequest(request: Request) {\n\tconst requestPath = new URL(request.url).pathname;\n\n\t// First, iterate through the routes (backwards) and execute \"middlewares\" on partial route matches\n\tfor (const route of [...routes].reverse()) {\n\t\tif (route.method && route.method !== request.method) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t// replaces with \"\\\\$&\", this prepends a backslash to the matched string, e.g. \"[\" becomes \"\\[\"\n\t\tconst routeMatcher = match(route.routePath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst mountMatcher = match(route.mountPath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst matchResult = routeMatcher(requestPath);\n\t\tconst mountMatchResult = mountMatcher(requestPath);\n\t\tif (matchResult && mountMatchResult) {\n\t\t\tfor (const handler of route.middlewares.flat()) {\n\t\t\t\tyield {\n\t\t\t\t\thandler,\n\t\t\t\t\tparams: matchResult.params as Params,\n\t\t\t\t\tpath: mountMatchResult.path,\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\n\t// Then look for the first exact route match and execute its \"modules\"\n\tfor (const route of routes) {\n\t\tif (route.method && route.method !== request.method) {\n\t\t\tcontinue;\n\t\t}\n\t\tconst routeMatcher = match(route.routePath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: true,\n\t\t});\n\t\tconst mountMatcher = match(route.mountPath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst matchResult = routeMatcher(requestPath);\n\t\tconst mountMatchResult = mountMatcher(requestPath);\n\t\tif (matchResult && mountMatchResult && route.modules.length) {\n\t\t\tfor (const handler of route.modules.flat()) {\n\t\t\t\tyield {\n\t\t\t\t\thandler,\n\t\t\t\t\tparams: matchResult.params as Params,\n\t\t\t\t\tpath: matchResult.path,\n\t\t\t\t};\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nexport default {\n\tasync fetch(\n\t\toriginalRequest: Request,\n\t\tenv: FetchEnv,\n\t\tworkerContext: WorkerContext\n\t) {\n\t\tlet request = originalRequest;\n\t\tconst handlerIterator = executeRequest(request);\n\t\tlet data = {}; // arbitrary data the user can set between functions\n\t\tlet isFailOpen = false;\n\n\t\tconst next = async (input?: RequestInfo, init?: RequestInit) => {\n\t\t\tif (input !== undefined) {\n\t\t\t\tlet url = input;\n\t\t\t\tif (typeof input === \"string\") {\n\t\t\t\t\turl = new URL(input, request.url).toString();\n\t\t\t\t}\n\t\t\t\trequest = new Request(url, init);\n\t\t\t}\n\n\t\t\tconst result = handlerIterator.next();\n\t\t\t// Note we can't use `!result.done` because this doesn't narrow to the correct type\n\t\t\tif (result.done === false) {\n\t\t\t\tconst { handler, params, path } = result.value;\n\t\t\t\tconst context = {\n\t\t\t\t\trequest: new Request(request.clone()),\n\t\t\t\t\tfunctionPath: path,\n\t\t\t\t\tnext,\n\t\t\t\t\tparams,\n\t\t\t\t\tget data() {\n\t\t\t\t\t\treturn data;\n\t\t\t\t\t},\n\t\t\t\t\tset data(value) {\n\t\t\t\t\t\tif (typeof value !== \"object\" || value === null) {\n\t\t\t\t\t\t\tthrow new Error(\"context.data must be an object\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// user has overriden context.data, so we need to merge it with the existing data\n\t\t\t\t\t\tdata = value;\n\t\t\t\t\t},\n\t\t\t\t\tenv,\n\t\t\t\t\twaitUntil: workerContext.waitUntil.bind(workerContext),\n\t\t\t\t\tpassThroughOnException: () => {\n\t\t\t\t\t\tisFailOpen = true;\n\t\t\t\t\t},\n\t\t\t\t};\n\n\t\t\t\tconst response = await handler(context);\n\n\t\t\t\tif (!(response instanceof Response)) {\n\t\t\t\t\tthrow new Error(\"Your Pages function should return a Response\");\n\t\t\t\t}\n\n\t\t\t\treturn cloneResponse(response);\n\t\t\t} else if (__FALLBACK_SERVICE__) {\n\t\t\t\t// There are no more handlers so finish with the fallback service (`env.ASSETS.fetch` in Pages' case)\n\t\t\t\tconst response = await env[__FALLBACK_SERVICE__].fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t} else {\n\t\t\t\t// There was not fallback service so actually make the request to the origin.\n\t\t\t\tconst response = await fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t}\n\t\t};\n\n\t\ttry {\n\t\t\treturn await next();\n\t\t} catch (error) {\n\t\t\tif (isFailOpen) {\n\t\t\t\tconst response = await env[__FALLBACK_SERVICE__].fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t}\n\n\t\t\tthrow error;\n\t\t}\n\t},\n};\n\n// This makes a Response mutable\nconst cloneResponse = (response: Response) =>\n\t// https://fetch.spec.whatwg.org/#null-body-status\n\tnew Response(\n\t\t[101, 204, 205, 304].includes(response.status) ? null : response.body,\n\t\tresponse\n\t);\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/Users/thaleslaray/.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/pages-template-worker.ts\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/Users/thaleslaray/.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"/Users/thaleslaray/.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"/Users/thaleslaray/.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/pages-template-worker.ts\";\n\t\t\t\tconst MIDDLEWARE_TEST_INJECT = \"__INJECT_FOR_TESTING_WRANGLER_MIDDLEWARE__\";\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/Users/thaleslaray/.wrangler/tmp/bundle-zzZZ55/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/Users/thaleslaray/.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/Users/thaleslaray/.wrangler/tmp/bundle-zzZZ55/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/Users/thaleslaray/.wrangler/tmp/bundle-zzZZ55/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/Users/thaleslaray/.wrangler/tmp/pages-nwR3f8/functionsWorker-0.2673311898216.mjs\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/Users/thaleslaray/.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"/Users/thaleslaray/.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"/Users/thaleslaray/.wrangler/tmp/pages-nwR3f8/functionsWorker-0.2673311898216.mjs\";\n\t\t\t\tconst MIDDLEWARE_TEST_INJECT = \"__INJECT_FOR_TESTING_WRANGLER_MIDDLEWARE__\";\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/Users/thaleslaray/code/projetos/hd/cloudflare-ocr-new/.wrangler/tmp/bundle-ZZAt42/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/Users/thaleslaray/.nvm/versions/node/v22.8.0/lib/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/Users/thaleslaray/code/projetos/hd/cloudflare-ocr-new/.wrangler/tmp/bundle-ZZAt42/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/Users/thaleslaray/code/projetos/hd/cloudflare-ocr-new/.wrangler/tmp/bundle-ZZAt42/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n"],
  "mappings": ";;;;;;AACA,eAAsB,cAAc,SAAS;AAC3C,QAAM,EAAE,SAAS,IAAI,IAAI;AAGzB,QAAM,cAAc;IAClB,+BAA+B;IAC/B,gCAAgC;IAChC,gCAAgC;EAClC;AAEA,MAAI;AAEF,UAAM,eAAe,QAAQ,QAAQ,IAAI,WAAW;AACpD,UAAM,SAAS,gBAAgB,IAAI;AAGnC,YAAQ,IAAI,qCAA8B,CAAC,CAAC,YAAY;AACxD,YAAQ,IAAI,kCAA2B,CAAC,CAAC,IAAI,eAAe;AAC5D,YAAQ,IAAI,4BAAqB,SAAS,GAAG,OAAO,UAAU,GAAG,EAAE,CAAC,QAAQ,MAAM;AAElF,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI,SAAS,KAAK,UAAU;QACjC,OAAO;MACT,CAAC,GAAG;QACF,QAAQ;QACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;MAChE,CAAC;IACH;AAGA,UAAM,WAAW,MAAM,QAAQ,SAAS;AACxC,UAAM,OAAO,SAAS,IAAI,MAAM;AAChC,UAAM,eAAe,SAAS,IAAI,YAAY;AAE9C,QAAI,YAAY;AAChB,QAAI,cAAc;AAChB,UAAI;AACF,oBAAY,KAAK,MAAM,YAAY;AACnC,gBAAQ,IAAI,+BAAwB,SAAS;MAC/C,SAAS,GAAG;AACV,gBAAQ,KAAK,+BAA+B,CAAC;MAC/C;IACF;AAEA,QAAI,CAAC,MAAM;AACT,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,yBAAyB,CAAC,GAAG;QACvE,QAAQ;QACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;MAChE,CAAC;IACH;AAKA,UAAM,YAAY,KAAK,IAAI;AAG3B,YAAQ,IAAI,qDAA2C;AACvD,UAAM,cAAc,KAAK,IAAI;AAE7B,UAAM,iBAAiB,IAAI,SAAS;AACpC,mBAAe,OAAO,WAAW,KAAK;AACtC,mBAAe,OAAO,QAAQ,IAAI;AAElC,UAAM,iBAAiB,MAAM,MAAM,mCAAmC;MACpE,QAAQ;MACR,SAAS;QACP,iBAAiB,UAAU,MAAM;MACnC;MACA,MAAM;IACR,CAAC;AAED,QAAI,CAAC,eAAe,IAAI;AACtB,YAAM,YAAY,MAAM,eAAe,KAAK;AAC5C,YAAM,IAAI,MAAM,kBAAkB,eAAe,MAAM,MAAM,SAAS,EAAE;IAC1E;AAEA,UAAM,eAAe,MAAM,eAAe,KAAK;AAC/C,UAAM,SAAS,aAAa;AAC5B,UAAM,aAAa,KAAK,IAAI,IAAI;AAChC,YAAQ,IAAI,8BAAyB,UAAU,iBAAiB,MAAM,EAAE;AAGxE,YAAQ,IAAI,2CAAoC;AAChD,UAAM,WAAW,KAAK,IAAI;AAE1B,UAAM,cAAc,MAAM,MAAM,mCAAmC,MAAM,kBAAkB;MACzF,SAAS;QACP,iBAAiB,UAAU,MAAM;QACjC,UAAU;MACZ;IACF,CAAC;AAED,QAAI,CAAC,YAAY,IAAI;AACnB,YAAM,YAAY,MAAM,YAAY,KAAK;AACzC,YAAM,IAAI,MAAM,0BAA0B,YAAY,MAAM,MAAM,SAAS,EAAE;IAC/E;AAEA,UAAM,YAAY,MAAM,YAAY,KAAK;AACzC,UAAM,YAAY,UAAU;AAC5B,UAAM,UAAU,KAAK,IAAI,IAAI;AAC7B,YAAQ,IAAI,2BAAsB,OAAO,IAAI;AAG7C,YAAQ,IAAI,oFAA6E;AACzF,UAAM,WAAW,KAAK,IAAI;AAG1B,UAAM,8BAA8B,gBAAAA,QAAA,CAACC,aAAY,UAAU;AACzD,UAAIA,YAAW;AACb,eAAO;UACL,MAAM;UACN,aAAa;YACX,MAAM;YACN,aAAa;YACb,QAAQ;cACN,MAAM;cACN,YAAY;gBACV,YAAY;kBACV,MAAM;kBACN,aAAa;gBACf;gBACA,mBAAmB;kBACjB,MAAM;kBACN,aAAa;gBACf;gBACA,SAAS;kBACP,MAAM;kBACN,aAAa;gBACf;cACF;cACA,UAAU,CAAC,cAAc,qBAAqB,SAAS;cACvD,sBAAsB;YACxB;YACA,QAAQ;UACV;QACF;MACF,OAAO;AACL,eAAO;UACL,MAAM;UACN,aAAa;YACX,MAAM;YACN,aAAa;YACb,QAAQ;cACN,MAAM;cACN,YAAY;gBACV,YAAY;kBACV,MAAM;kBACN,aAAa;gBACf;gBACA,mBAAmB;kBACjB,MAAM;kBACN,aAAa;gBACf;gBACA,SAAS;kBACP,MAAM;kBACN,aAAa;gBACf;cACF;cACA,UAAU,CAAC,cAAc,qBAAqB,SAAS;cACvD,sBAAsB;YACxB;YACA,QAAQ;UACV;QACF;MACF;IACF,GA1DoC,6BAAA;AA6DpC,YAAQ,IAAI,kDAA2C;AACvD,UAAM,2BAA2B;MAC/B,OAAO;MACP,UAAU;QACR,MAAM;QACN,cAAc;MAChB;MACA,sBAAsB;;IACxB;AAEA,UAAM,mBAAmB,MAAM,MAAM,iCAAiC;MACpE,QAAQ;MACR,SAAS;QACP,iBAAiB,UAAU,MAAM;QACjC,gBAAgB;MAClB;MACA,MAAM,KAAK,UAAU,wBAAwB;IAC/C,CAAC;AAED,QAAI,CAAC,iBAAiB,IAAI;AACxB,YAAM,YAAY,MAAM,iBAAiB,KAAK;AAC9C,YAAM,IAAI,MAAM,8BAA8B,iBAAiB,MAAM,MAAM,SAAS,EAAE;IACxF;AAEA,UAAM,iBAAiB,MAAM,iBAAiB,KAAK;AAGnD,UAAM,iBAAiB,eAAe,QAAQ,CAAC,GAAG,YAAY,IAAI,YAAY;AAC9E,UAAM,kBAAkB,cAAc,MAAM,6FAA6F,KAAK,CAAC,GAAG;AAClJ,UAAM,qBAAqB,cAAc,MAAM,iHAAiH,KAAK,CAAC,GAAG;AAEzK,UAAM,eAAe;AACrB,UAAM,YAAY,iBAAiB,gBAAgB,iBAAiB,oBAAoB;AAExF,YAAQ,IAAI,0BAA0B,cAAc,SAAS,iBAAiB,EAAE;AAChF,YAAQ,IAAI,sBAAsB,YAAY,YAAY,YAAY,EAAE;AAGxE,YAAQ,IAAI,4EAAqE;AACjF,UAAM,iBAAiB;MACrB,OAAO;MACP,UAAU;QACR,MAAM;QACN,cAAc;MAChB;MACA,sBAAsB;MACtB,wBAAwB,4BAA4B,SAAS;IAC/D;AAIA,QAAI,aAAa,UAAU,WAAW;AACpC,cAAQ,IAAI,8BAAuB,UAAU,WAAW,IAAI,UAAU,WAAW,4BAA4B,UAAU,SAAS,IAAI,UAAU,OAAO,GAAG;IAC1J;AAEA,UAAM,cAAc,MAAM,MAAM,iCAAiC;MAC/D,QAAQ;MACR,SAAS;QACP,iBAAiB,UAAU,MAAM;QACjC,gBAAgB;MAClB;MACA,MAAM,KAAK,UAAU,cAAc;IACrC,CAAC;AAED,QAAI,CAAC,YAAY,IAAI;AACnB,YAAM,YAAY,MAAM,YAAY,KAAK;AACzC,YAAM,IAAI,MAAM,0BAA0B,YAAY,MAAM,MAAM,SAAS,EAAE;IAC/E;AAEA,UAAM,YAAY,MAAM,YAAY,KAAK;AACzC,UAAM,UAAU,KAAK,IAAI,IAAI;AAC7B,UAAM,YAAY,KAAK,IAAI,IAAI;AAE/B,YAAQ,IAAI,2BAAsB,OAAO,IAAI;AAC7C,YAAQ,IAAI,oCAA6B,SAAS,IAAI;AACtD,YAAQ,IAAI,sCAA+B,KAAK,UAAU,WAAW,MAAM,CAAC,CAAC;AAG7E,QAAI,kBAAkB;AACtB,QAAI,UAAU,SAAS,UAAU,MAAM,SAAS,GAAG;AAEjD,UAAI,WAAW,qBAAqB;AAEpC,UAAI,WAAW;AACb,oBAAY;AACZ,8BAAsB;AACtB,uBAAe;MACjB,OAAO;AACL,oBAAY;AACZ,8BAAsB;AACtB,uBAAe;MACjB;AAGA,wBAAkB,UAAU,MAAM,IAAI,CAAC,MAAM,UAAU;AACrD,cAAM,aAAa,QAAQ;AAG3B,YAAI,cAAc;AAClB,YAAI,QAAQ,GAAG;AAEb,yBAAe;QACjB;AAGA,uBAAe,gBAAS,SAAS,IAAI,UAAU;;;AAG/C,YAAI,UAAU,KAAK,YAAY;AAG/B,kBAAU,QAAQ,QAAQ,8EAA8E,EAAE;AAE1G,uBAAe;AAGf,YAAI,KAAK,UAAU,KAAK,OAAO,SAAS,GAAG;AACzC,gBAAM,oBAAoB,KAAK,OAC5B,OAAO,CAAA,QAAO,IAAI,gBAAgB,EAClC,IAAI,CAAA,QAAO;AACV,gBAAI;AACF,oBAAM,aAAa,OAAO,IAAI,qBAAqB,WAC/C,KAAK,MAAM,IAAI,gBAAgB,IAC/B,IAAI;AAGR,qBAAO,OAAO,WAAW,WAAW,YAAY,CAAC,OAAO,WAAW,iBAAiB;;IAAU,WAAW,OAAO;YAClH,SAAS,GAAG;AACV,sBAAQ,IAAI,+CAAyC,CAAC;AACtD,qBAAO,gBAAgB,IAAI,gBAAgB;YAC7C;UACF,CAAC;AAEH,cAAI,kBAAkB,SAAS,GAAG;AAEhC,2BAAe;;MAAW,mBAAmB;;IAAS,kBAAkB,KAAK,MAAM;UACrF;QACF;AAEA,eAAO;MACT,CAAC,EAAE,KAAK,MAAM;AAEd,cAAQ,IAAI,uBAAgB,UAAU,MAAM,MAAM,mBAAmB;IACvE,OAAO;AAEL,wBAAkB,UAAU,WAAW,UAAU,QAAQ,UAAU,YAAY,KAAK,UAAU,WAAW,MAAM,CAAC;IAClH;AAEA,UAAM,WAAW;MACf,SAAS;MACT,UAAU;MACV,UAAU,KAAK;MACf,QAAQ;MACR,QAAQ;QACN,QAAQ;QACR,KAAK;QACL,KAAK;QACL,OAAO;MACT;MACA,OAAO;QACL,OAAO,UAAU,OAAO,UAAU;QAClC,UAAU,KAAK;QACf,OAAO,UAAU;MACnB;IACF;AAGA,QAAI,WAAW;AACb,eAAS,YAAY;AACrB,eAAS,YAAY;IACvB;AAEA,WAAO,IAAI,SAAS,KAAK,UAAU,QAAQ,GAAG;MAC5C,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;IAChE,CAAC;EAEH,SAAS,OAAO;AACd,YAAQ,MAAM,qBAAqB,KAAK;AACxC,WAAO,IAAI,SAAS,KAAK,UAAU;MACjC,SAAS;MACT,OAAO,0BAA0B,MAAM,OAAO;IAChD,CAAC,GAAG;MACF,QAAQ;MACR,SAAS,EAAE,GAAG,aAAa,gBAAgB,mBAAmB;IAChE,CAAC;EACH;AACF;AAnWsB;AAAAD,QAAA,eAAA,eAAA;AAsWtB,eAAsB,mBAAmB;AACvC,SAAO,IAAI,SAAS,MAAM;IACxB,SAAS;MACP,+BAA+B;MAC/B,gCAAgC;MAChC,gCAAgC;IAClC;EACF,CAAC;AACH;AARsB;AAAAA,QAAA,kBAAA,kBAAA;ACpWf,IAAM,SAAS;EAClB;IACE,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAAC,gBAA6B;EACzC;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAAC,aAA0B;EACtC;AACF;ACEF,SAAS,MAAM,KAAW;AACxB,MAAM,SAAqB,CAAA;AAC3B,MAAI,IAAI;AAER,SAAO,IAAI,IAAI,QAAQ;AACrB,QAAM,OAAO,IAAI,CAAC;AAElB,QAAI,SAAS,OAAO,SAAS,OAAO,SAAS,KAAK;AAChD,aAAO,KAAK,EAAE,MAAM,YAAY,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AAC3D;;AAGF,QAAI,SAAS,MAAM;AACjB,aAAO,KAAK,EAAE,MAAM,gBAAgB,OAAO,KAAK,OAAO,IAAI,GAAG,EAAC,CAAE;AACjE;;AAGF,QAAI,SAAS,KAAK;AAChB,aAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AACvD;;AAGF,QAAI,SAAS,KAAK;AAChB,aAAO,KAAK,EAAE,MAAM,SAAS,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AACxD;;AAGF,QAAI,SAAS,KAAK;AAChB,UAAI,OAAO;AACX,UAAI,IAAI,IAAI;AAEZ,aAAO,IAAI,IAAI,QAAQ;AACrB,YAAM,OAAO,IAAI,WAAW,CAAC;AAE7B;;UAEG,QAAQ,MAAM,QAAQ;UAEtB,QAAQ,MAAM,QAAQ;UAEtB,QAAQ,MAAM,QAAQ;UAEvB,SAAS;UACT;AACA,kBAAQ,IAAI,GAAG;AACf;;AAGF;;AAGF,UAAI,CAAC;AAAM,cAAM,IAAI,UAAU,6BAAA,OAA6B,CAAC,CAAE;AAE/D,aAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,KAAI,CAAE;AACnD,UAAI;AACJ;;AAGF,QAAI,SAAS,KAAK;AAChB,UAAI,QAAQ;AACZ,UAAI,UAAU;AACd,UAAI,IAAI,IAAI;AAEZ,UAAI,IAAI,CAAC,MAAM,KAAK;AAClB,cAAM,IAAI,UAAU,oCAAA,OAAoC,CAAC,CAAE;;AAG7D,aAAO,IAAI,IAAI,QAAQ;AACrB,YAAI,IAAI,CAAC,MAAM,MAAM;AACnB,qBAAW,IAAI,GAAG,IAAI,IAAI,GAAG;AAC7B;;AAGF,YAAI,IAAI,CAAC,MAAM,KAAK;AAClB;AACA,cAAI,UAAU,GAAG;AACf;AACA;;mBAEO,IAAI,CAAC,MAAM,KAAK;AACzB;AACA,cAAI,IAAI,IAAI,CAAC,MAAM,KAAK;AACtB,kBAAM,IAAI,UAAU,uCAAA,OAAuC,CAAC,CAAE;;;AAIlE,mBAAW,IAAI,GAAG;;AAGpB,UAAI;AAAO,cAAM,IAAI,UAAU,yBAAA,OAAyB,CAAC,CAAE;AAC3D,UAAI,CAAC;AAAS,cAAM,IAAI,UAAU,sBAAA,OAAsB,CAAC,CAAE;AAE3D,aAAO,KAAK,EAAE,MAAM,WAAW,OAAO,GAAG,OAAO,QAAO,CAAE;AACzD,UAAI;AACJ;;AAGF,WAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;;AAGzD,SAAO,KAAK,EAAE,MAAM,OAAO,OAAO,GAAG,OAAO,GAAE,CAAE;AAEhD,SAAO;AACT;AAvGS;AAAAA,QAAA,OAAA,OAAA;AAuHH,SAAU,MAAM,KAAa,SAA0B;AAA1B,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAA0B;AAC3D,MAAM,SAAS,MAAM,GAAG;AAChB,MAAA,KAAuC,QAAO,UAA9C,WAAQ,OAAA,SAAG,OAAI,IAAE,KAAsB,QAAO,WAA7B,YAAS,OAAA,SAAG,QAAK;AAC1C,MAAM,SAAkB,CAAA;AACxB,MAAI,MAAM;AACV,MAAI,IAAI;AACR,MAAI,OAAO;AAEX,MAAM,aAAa,gBAAAA,QAAA,SAAC,MAAsB;AACxC,QAAI,IAAI,OAAO,UAAU,OAAO,CAAC,EAAE,SAAS;AAAM,aAAO,OAAO,GAAG,EAAE;EACvE,GAFmB,YAAA;AAInB,MAAM,cAAc,gBAAAA,QAAA,SAAC,MAAsB;AACzC,QAAME,SAAQ,WAAW,IAAI;AAC7B,QAAIA,WAAU;AAAW,aAAOA;AAC1B,QAAAC,MAA4B,OAAO,CAAC,GAA5B,WAAQA,IAAA,MAAE,QAAKA,IAAA;AAC7B,UAAM,IAAI,UAAU,cAAA,OAAc,UAAQ,MAAA,EAAA,OAAO,OAAK,aAAA,EAAA,OAAc,IAAI,CAAE;EAC5E,GALoB,aAAA;AAOpB,MAAM,cAAc,gBAAAH,QAAA,WAAA;AAClB,QAAII,UAAS;AACb,QAAIF;AACJ,WAAQA,SAAQ,WAAW,MAAM,KAAK,WAAW,cAAc,GAAI;AACjEE,iBAAUF;;AAEZ,WAAOE;EACT,GAPoB,aAAA;AASpB,MAAM,SAAS,gBAAAJ,QAAA,SAACE,QAAa;AAC3B,aAAmB,KAAA,GAAA,cAAA,WAAA,KAAA,YAAA,QAAA,MAAS;AAAvB,UAAMG,QAAI,YAAA,EAAA;AAAe,UAAIH,OAAM,QAAQG,KAAI,IAAI;AAAI,eAAO;;AACnE,WAAO;EACT,GAHe,QAAA;AAKf,MAAM,cAAc,gBAAAL,QAAA,SAACM,SAAc;AACjC,QAAM,OAAO,OAAO,OAAO,SAAS,CAAC;AACrC,QAAM,WAAWA,YAAW,QAAQ,OAAO,SAAS,WAAW,OAAO;AAEtE,QAAI,QAAQ,CAAC,UAAU;AACrB,YAAM,IAAI,UACR,8DAAA,OAA+D,KAAa,MAAI,GAAA,CAAG;;AAIvF,QAAI,CAAC,YAAY,OAAO,QAAQ;AAAG,aAAO,KAAA,OAAK,aAAa,SAAS,GAAC,KAAA;AACtE,WAAO,SAAA,OAAS,aAAa,QAAQ,GAAC,KAAA,EAAA,OAAM,aAAa,SAAS,GAAC,MAAA;EACrE,GAZoB,aAAA;AAcpB,SAAO,IAAI,OAAO,QAAQ;AACxB,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAM,UAAU,WAAW,SAAS;AAEpC,QAAI,QAAQ,SAAS;AACnB,UAAI,SAAS,QAAQ;AAErB,UAAI,SAAS,QAAQ,MAAM,MAAM,IAAI;AACnC,gBAAQ;AACR,iBAAS;;AAGX,UAAI,MAAM;AACR,eAAO,KAAK,IAAI;AAChB,eAAO;;AAGT,aAAO,KAAK;QACV,MAAM,QAAQ;QACd;QACA,QAAQ;QACR,SAAS,WAAW,YAAY,MAAM;QACtC,UAAU,WAAW,UAAU,KAAK;OACrC;AACD;;AAGF,QAAM,QAAQ,QAAQ,WAAW,cAAc;AAC/C,QAAI,OAAO;AACT,cAAQ;AACR;;AAGF,QAAI,MAAM;AACR,aAAO,KAAK,IAAI;AAChB,aAAO;;AAGT,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAI,MAAM;AACR,UAAM,SAAS,YAAW;AAC1B,UAAM,SAAO,WAAW,MAAM,KAAK;AACnC,UAAM,YAAU,WAAW,SAAS,KAAK;AACzC,UAAM,SAAS,YAAW;AAE1B,kBAAY,OAAO;AAEnB,aAAO,KAAK;QACV,MAAM,WAAS,YAAU,QAAQ;QACjC,SAAS,UAAQ,CAAC,YAAU,YAAY,MAAM,IAAI;QAClD;QACA;QACA,UAAU,WAAW,UAAU,KAAK;OACrC;AACD;;AAGF,gBAAY,KAAK;;AAGnB,SAAO;AACT;AA7GgB;AAAAN,QAAA,OAAA,OAAA;AA4PV,SAAU,MACd,KACA,SAAwE;AAExE,MAAM,OAAc,CAAA;AACpB,MAAM,KAAK,aAAa,KAAK,MAAM,OAAO;AAC1C,SAAO,iBAAoB,IAAI,MAAM,OAAO;AAC9C;AAPgB;AAAAA,QAAA,OAAA,OAAA;AAYV,SAAU,iBACd,IACA,MACA,SAAqC;AAArC,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAAqC;AAE7B,MAAA,KAA8B,QAAO,QAArC,SAAM,OAAA,SAAG,SAAC,GAAS;AAAK,WAAA;EAAA,IAAC;AAEjC,SAAO,SAAU,UAAgB;AAC/B,QAAM,IAAI,GAAG,KAAK,QAAQ;AAC1B,QAAI,CAAC;AAAG,aAAO;AAEP,QAAG,OAAgB,EAAC,CAAA,GAAX,QAAU,EAAC;AAC5B,QAAM,SAAS,uBAAO,OAAO,IAAI;mDAExBO,IAAC;AACR,UAAI,EAAEA,EAAC,MAAM;;AAEb,UAAM,MAAM,KAAKA,KAAI,CAAC;AAEtB,UAAI,IAAI,aAAa,OAAO,IAAI,aAAa,KAAK;AAChD,eAAO,IAAI,IAAI,IAAI,EAAEA,EAAC,EAAE,MAAM,IAAI,SAAS,IAAI,MAAM,EAAE,IAAI,SAAC,OAAK;AAC/D,iBAAO,OAAO,OAAO,GAAG;QAC1B,CAAC;aACI;AACL,eAAO,IAAI,IAAI,IAAI,OAAO,EAAEA,EAAC,GAAG,GAAG;;;AAVvC,aAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAG;cAAxB,CAAC;;AAcV,WAAO,EAAE,MAAM,OAAO,OAAM;EAC9B;AACF;AA9BgB;AAAAP,QAAA,kBAAA,kBAAA;AAmChB,SAAS,aAAa,KAAW;AAC/B,SAAO,IAAI,QAAQ,6BAA6B,MAAM;AACxD;AAFS;AAAAA,QAAA,cAAA,cAAA;AAOT,SAAS,MAAM,SAAiC;AAC9C,SAAO,WAAW,QAAQ,YAAY,KAAK;AAC7C;AAFS;AAAAA,QAAA,OAAA,OAAA;AAuBT,SAAS,eAAe,MAAc,MAAY;AAChD,MAAI,CAAC;AAAM,WAAO;AAElB,MAAM,cAAc;AAEpB,MAAI,QAAQ;AACZ,MAAI,aAAa,YAAY,KAAK,KAAK,MAAM;AAC7C,SAAO,YAAY;AACjB,SAAK,KAAK;;MAER,MAAM,WAAW,CAAC,KAAK;MACvB,QAAQ;MACR,QAAQ;MACR,UAAU;MACV,SAAS;KACV;AACD,iBAAa,YAAY,KAAK,KAAK,MAAM;;AAG3C,SAAO;AACT;AApBS;AAAAA,QAAA,gBAAA,gBAAA;AAyBT,SAAS,cACP,OACA,MACA,SAA8C;AAE9C,MAAM,QAAQ,MAAM,IAAI,SAAC,MAAI;AAAK,WAAA,aAAa,MAAM,MAAM,OAAO,EAAE;EAAlC,CAAwC;AAC1E,SAAO,IAAI,OAAO,MAAA,OAAM,MAAM,KAAK,GAAG,GAAC,GAAA,GAAK,MAAM,OAAO,CAAC;AAC5D;AAPS;AAAAA,QAAA,eAAA,eAAA;AAYT,SAAS,eACP,MACA,MACA,SAA8C;AAE9C,SAAO,eAAe,MAAM,MAAM,OAAO,GAAG,MAAM,OAAO;AAC3D;AANS;AAAAA,QAAA,gBAAA,gBAAA;AA0CH,SAAU,eACd,QACA,MACA,SAAmC;AAAnC,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAAmC;AAGjC,MAAA,KAME,QAAO,QANT,SAAM,OAAA,SAAG,QAAK,IACd,KAKE,QAAO,OALT,QAAK,OAAA,SAAG,OAAI,IACZ,KAIE,QAAO,KAJT,MAAG,OAAA,SAAG,OAAI,IACV,KAGE,QAAO,QAHT,SAAM,OAAA,SAAG,SAAC,GAAS;AAAK,WAAA;EAAA,IAAC,IACzB,KAEE,QAAO,WAFT,YAAS,OAAA,SAAG,QAAK,IACjB,KACE,QAAO,UADT,WAAQ,OAAA,SAAG,KAAE;AAEf,MAAM,aAAa,IAAA,OAAI,aAAa,QAAQ,GAAC,KAAA;AAC7C,MAAM,cAAc,IAAA,OAAI,aAAa,SAAS,GAAC,GAAA;AAC/C,MAAI,QAAQ,QAAQ,MAAM;AAG1B,WAAoB,KAAA,GAAA,WAAA,QAAA,KAAA,SAAA,QAAA,MAAQ;AAAvB,QAAM,QAAK,SAAA,EAAA;AACd,QAAI,OAAO,UAAU,UAAU;AAC7B,eAAS,aAAa,OAAO,KAAK,CAAC;WAC9B;AACL,UAAM,SAAS,aAAa,OAAO,MAAM,MAAM,CAAC;AAChD,UAAM,SAAS,aAAa,OAAO,MAAM,MAAM,CAAC;AAEhD,UAAI,MAAM,SAAS;AACjB,YAAI;AAAM,eAAK,KAAK,KAAK;AAEzB,YAAI,UAAU,QAAQ;AACpB,cAAI,MAAM,aAAa,OAAO,MAAM,aAAa,KAAK;AACpD,gBAAM,MAAM,MAAM,aAAa,MAAM,MAAM;AAC3C,qBAAS,MAAA,OAAM,QAAM,MAAA,EAAA,OAAO,MAAM,SAAO,MAAA,EAAA,OAAO,MAAM,EAAA,OAAG,QAAM,KAAA,EAAA,OAAM,MAAM,SAAO,MAAA,EAAA,OAAO,QAAM,GAAA,EAAA,OAAI,GAAG;iBACjG;AACL,qBAAS,MAAA,OAAM,QAAM,GAAA,EAAA,OAAI,MAAM,SAAO,GAAA,EAAA,OAAI,QAAM,GAAA,EAAA,OAAI,MAAM,QAAQ;;eAE/D;AACL,cAAI,MAAM,aAAa,OAAO,MAAM,aAAa,KAAK;AACpD,kBAAM,IAAI,UACR,mBAAA,OAAmB,MAAM,MAAI,+BAAA,CAA+B;;AAIhE,mBAAS,IAAA,OAAI,MAAM,SAAO,GAAA,EAAA,OAAI,MAAM,QAAQ;;aAEzC;AACL,iBAAS,MAAA,OAAM,MAAM,EAAA,OAAG,QAAM,GAAA,EAAA,OAAI,MAAM,QAAQ;;;;AAKtD,MAAI,KAAK;AACP,QAAI,CAAC;AAAQ,eAAS,GAAA,OAAG,aAAW,GAAA;AAEpC,aAAS,CAAC,QAAQ,WAAW,MAAM,MAAA,OAAM,YAAU,GAAA;SAC9C;AACL,QAAM,WAAW,OAAO,OAAO,SAAS,CAAC;AACzC,QAAM,iBACJ,OAAO,aAAa,WAChB,YAAY,QAAQ,SAAS,SAAS,SAAS,CAAC,CAAC,IAAI,KACrD,aAAa;AAEnB,QAAI,CAAC,QAAQ;AACX,eAAS,MAAA,OAAM,aAAW,KAAA,EAAA,OAAM,YAAU,KAAA;;AAG5C,QAAI,CAAC,gBAAgB;AACnB,eAAS,MAAA,OAAM,aAAW,GAAA,EAAA,OAAI,YAAU,GAAA;;;AAI5C,SAAO,IAAI,OAAO,OAAO,MAAM,OAAO,CAAC;AACzC;AAvEgB;AAAAA,QAAA,gBAAA,gBAAA;AAqFV,SAAU,aACd,MACA,MACA,SAA8C;AAE9C,MAAI,gBAAgB;AAAQ,WAAO,eAAe,MAAM,IAAI;AAC5D,MAAI,MAAM,QAAQ,IAAI;AAAG,WAAO,cAAc,MAAM,MAAM,OAAO;AACjE,SAAO,eAAe,MAAM,MAAM,OAAO;AAC3C;AARgB;AAAAA,QAAA,cAAA,cAAA;ACrnBhB,IAAM,cAAc;AAwDpB,UAAU,eAAe,SAAkB;AAC1C,QAAM,cAAc,IAAI,IAAI,QAAQ,GAAG,EAAE;AAGzC,aAAW,SAAS,CAAC,GAAG,MAAM,EAAE,QAAQ,GAAG;AAC1C,QAAI,MAAM,UAAU,MAAM,WAAW,QAAQ,QAAQ;AACpD;IACD;AAGA,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;MACxE,KAAK;IACN,CAAC;AACD,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;MACxE,KAAK;IACN,CAAC;AACD,UAAM,cAAc,aAAa,WAAW;AAC5C,UAAM,mBAAmB,aAAa,WAAW;AACjD,QAAI,eAAe,kBAAkB;AACpC,iBAAW,WAAW,MAAM,YAAY,KAAK,GAAG;AAC/C,cAAM;UACL;UACA,QAAQ,YAAY;UACpB,MAAM,iBAAiB;QACxB;MACD;IACD;EACD;AAGA,aAAW,SAAS,QAAQ;AAC3B,QAAI,MAAM,UAAU,MAAM,WAAW,QAAQ,QAAQ;AACpD;IACD;AACA,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;MACxE,KAAK;IACN,CAAC;AACD,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;MACxE,KAAK;IACN,CAAC;AACD,UAAM,cAAc,aAAa,WAAW;AAC5C,UAAM,mBAAmB,aAAa,WAAW;AACjD,QAAI,eAAe,oBAAoB,MAAM,QAAQ,QAAQ;AAC5D,iBAAW,WAAW,MAAM,QAAQ,KAAK,GAAG;AAC3C,cAAM;UACL;UACA,QAAQ,YAAY;UACpB,MAAM,YAAY;QACnB;MACD;AACA;IACD;EACD;AACD;AArDU;AAAAA,QAAA,gBAAA,gBAAA;AAuDV,IAAO,gCAAQ;EACd,MAAM,MACL,iBACA,KACA,eACC;AACD,QAAI,UAAU;AACd,UAAM,kBAAkB,eAAe,OAAO;AAC9C,QAAI,OAAO,CAAC;AACZ,QAAI,aAAa;AAEjB,UAAM,OAAO,gBAAAA,QAAA,OAAO,OAAqB,SAAuB;AAC/D,UAAI,UAAU,QAAW;AACxB,YAAI,MAAM;AACV,YAAI,OAAO,UAAU,UAAU;AAC9B,gBAAM,IAAI,IAAI,OAAO,QAAQ,GAAG,EAAE,SAAS;QAC5C;AACA,kBAAU,IAAI,QAAQ,KAAK,IAAI;MAChC;AAEA,YAAM,SAAS,gBAAgB,KAAK;AAEpC,UAAI,OAAO,SAAS,OAAO;AAC1B,cAAM,EAAE,SAAS,QAAQ,KAAK,IAAI,OAAO;AACzC,cAAM,UAAU;UACf,SAAS,IAAI,QAAQ,QAAQ,MAAM,CAAC;UACpC,cAAc;UACd;UACA;UACA,IAAI,OAAO;AACV,mBAAO;UACR;UACA,IAAI,KAAK,OAAO;AACf,gBAAI,OAAO,UAAU,YAAY,UAAU,MAAM;AAChD,oBAAM,IAAI,MAAM,gCAAgC;YACjD;AAEA,mBAAO;UACR;UACA;UACA,WAAW,cAAc,UAAU,KAAK,aAAa;UACrD,wBAAwB,gBAAAA,QAAA,MAAM;AAC7B,yBAAa;UACd,GAFwB,wBAAA;QAGzB;AAEA,cAAM,WAAW,MAAM,QAAQ,OAAO;AAEtC,YAAI,EAAE,oBAAoB,WAAW;AACpC,gBAAM,IAAI,MAAM,8CAA8C;QAC/D;AAEA,eAAO,cAAc,QAAQ;MAC9B,WAAW,UAAsB;AAEhC,cAAM,WAAW,MAAM,IAAI,QAAoB,EAAE,MAAM,OAAO;AAC9D,eAAO,cAAc,QAAQ;MAC9B,OAAO;AAEN,cAAM,WAAW,MAAM,MAAM,OAAO;AACpC,eAAO,cAAc,QAAQ;MAC9B;IACD,GAnDa,MAAA;AAqDb,QAAI;AACH,aAAO,MAAM,KAAK;IACnB,SAAS,OAAO;AACf,UAAI,YAAY;AACf,cAAM,WAAW,MAAM,IAAI,QAAoB,EAAE,MAAM,OAAO;AAC9D,eAAO,cAAc,QAAQ;MAC9B;AAEA,YAAM;IACP;EACD;AACD;AAGA,IAAM,gBAAgB,gBAAAA,QAAA,CAAC;;EAEtB,IAAI;IACH,CAAC,KAAK,KAAK,KAAK,GAAG,EAAE,SAAS,SAAS,MAAM,IAAI,OAAO,SAAS;IACjE;EACD;GALqB,eAAA;AC9LtB,IAAM,YAAwB,gBAAAA,QAAA,OAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;EAC7C,UAAA;AACC,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;QAAC;MACtC;IACD,SAAS,GAAG;AACX,cAAQ,MAAM,4CAA4C,CAAC;IAC5D;EACD;AACD,GAb8B,WAAA;AAe9B,IAAO,6CAAQ;ACRf,SAAS,YAAY,GAAmB;AACvC,SAAO;IACN,MAAM,GAAG;IACT,SAAS,GAAG,WAAW,OAAO,CAAC;IAC/B,OAAO,GAAG;IACV,OAAO,GAAG,UAAU,SAAY,SAAY,YAAY,EAAE,KAAK;EAChE;AACD;AAPS;AAAAA,QAAA,aAAA,aAAA;AAUT,IAAM,YAAwB,gBAAAA,QAAA,OAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;EAC7C,SAAS,GAAQ;AAChB,UAAM,QAAQ,YAAY,CAAC;AAC3B,WAAO,SAAS,KAAK,OAAO;MAC3B,QAAQ;MACR,SAAS,EAAE,+BAA+B,OAAO;IAClD,CAAC;EACF;AACD,GAV8B,WAAA;AAY9B,IAAO,2CAAQ;ACzBJ,IAAM,mCAAmC;EAE9B;EAAyB;AAC3C;AACA,IAAO,sCAAQ;ACcnB,IAAM,wBAAsC,CAAC;AAKtC,SAAS,uBAAuB,MAAqC;AAC3E,wBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB;AAAAA,QAAA,qBAAA,qBAAA;AAShB,SAAS,uBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;IACxC;IACA,KAAK,YAAY,QAAQ;AACxB,aAAO,uBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;IACtE;EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS;AAAAA,QAAA,wBAAA,wBAAA;AAiBF,SAAS,kBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAO,uBAAuB,SAAS,KAAK,KAAK,UAAU;IAC1D,GAAG;IACH;EACD,CAAC;AACF;AAXgB;AAAAA,QAAA,mBAAA,mBAAA;AC3ChB,IAAM,iCAAN,MAAM,gCAA8D;SAAA;;;EAGnE,YACU,eACA,MACT,SACC;AAHQ,SAAA,gBAAA;AACA,SAAA,OAAA;AAGT,SAAK,WAAW;EACjB;EArBD,OAYoE;AAAA,IAAAA,QAAA,MAAA,gCAAA;EAAA;EAC1D;EAUT,UAAU;AACT,QAAI,EAAE,gBAAgB,kCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;IACzC;AAEA,SAAK,SAAS;EACf;AACD;AAEA,SAAS,oBAAoB,QAA0C;AAEtE,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;EAC/B;AAEA,QAAM,kBAA+C,gBAAAA,QAAA,SACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;EACtC,GATqD,iBAAA;AAWrD,SAAO;IACN,GAAG;IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gBAAAA,QAAA,SAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAI;YACtB,KAAK,IAAI;YACT,KAAK,QAAQ;YACb,MAAM;YAAC;UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;QAC7C;MACD,GAT+B,YAAA;AAU/B,aAAO,kBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;IACxE;EACD;AACD;AAxCS;AAAAA,QAAA,qBAAA,qBAAA;AA0CT,SAAS,qBACR,OAC8B;AAE9B,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;EAC/B;AAGA,SAAO,cAAc,MAAM;IAC1B,mBAAyE,gBAAAA,QAAA,CACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;MACvE;AACA,aAAO,MAAM,MAAM,OAAO;IAC3B,GAXyE,kBAAA;IAazE,cAA0B,gBAAAA,QAAA,CAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAI;UACtB,KAAK,IAAI;UACT,KAAK,QAAQ;UACb,MAAM;UAAC;QACR;AACA,eAAO,MAAM,UAAU,UAAU;MAClC;IACD,GAT0B,aAAA;IAW1B,MAAM,SAAwD;AAC7D,aAAO;QACN;QACA,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;MACN;IACD;EACD;AACD;AAnDS;AAAAA,QAAA,sBAAA,sBAAA;AAqDT,IAAI;AACJ,IAAI,OAAO,wCAAU,UAAU;AAC9B,kBAAgB,oBAAoB,mCAAK;AAC1C,WAAW,OAAO,wCAAU,YAAY;AACvC,kBAAgB,qBAAqB,mCAAK;AAC3C;AACA,IAAO,kCAAQ;;;ACnIf,IAAMQ,aAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,UAAE;AACD,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;AAAA,QAAC;AAAA,MACtC;AAAA,IACD,SAAS,GAAG;AACX,cAAQ,MAAM,4CAA4C,CAAC;AAAA,IAC5D;AAAA,EACD;AACD,GAb8B;AAe9B,IAAOC,8CAAQD;;;ACRf,SAASE,aAAY,GAAmB;AACvC,SAAO;AAAA,IACN,MAAM,GAAG;AAAA,IACT,SAAS,GAAG,WAAW,OAAO,CAAC;AAAA,IAC/B,OAAO,GAAG;AAAA,IACV,OAAO,GAAG,UAAU,SAAY,SAAYA,aAAY,EAAE,KAAK;AAAA,EAChE;AACD;AAPS,OAAAA,cAAA;AAUT,IAAMC,aAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,SAAS,GAAQ;AAChB,UAAM,QAAQD,aAAY,CAAC;AAC3B,WAAO,SAAS,KAAK,OAAO;AAAA,MAC3B,QAAQ;AAAA,MACR,SAAS,EAAE,+BAA+B,OAAO;AAAA,IAClD,CAAC;AAAA,EACF;AACD,GAV8B;AAY9B,IAAOE,4CAAQD;;;ACzBJ,IAAME,oCAAmC;AAAA,EAE9BC;AAAA,EAAyBC;AAC3C;AACA,IAAOC,uCAAQ;;;ACcnB,IAAMC,yBAAsC,CAAC;AAKtC,SAASC,wBAAuB,MAAqC;AAC3E,EAAAD,uBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB,OAAAC,sBAAA;AAShB,SAASC,wBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;AAAA,IACxC;AAAA,IACA,KAAK,YAAY,QAAQ;AACxB,aAAOA,wBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;AAAA,IACtE;AAAA,EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS,OAAAA,yBAAA;AAiBF,SAASC,mBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAOD,wBAAuB,SAAS,KAAK,KAAK,UAAU;AAAA,IAC1D,GAAGE;AAAA,IACH;AAAA,EACD,CAAC;AACF;AAXgB,OAAAD,oBAAA;;;AC3ChB,IAAME,kCAAN,MAAMC,iCAA8D;AAAA,EAGnE,YACU,eACA,MACT,SACC;AAHQ;AACA;AAGT,SAAK,WAAW;AAAA,EACjB;AAAA,EArBD,OAYoE;AAAA;AAAA;AAAA,EAC1D;AAAA,EAUT,UAAU;AACT,QAAI,EAAE,gBAAgBA,mCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;AAAA,IACzC;AAEA,SAAK,SAAS;AAAA,EACf;AACD;AAEA,SAASC,qBAAoB,QAA0C;AAEtE,MACCC,sCAAqC,UACrCA,kCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAcA,mCAAkC;AAC1D,IAAAC,qBAAoB,UAAU;AAAA,EAC/B;AAEA,QAAM,kBAA+C,gCACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;AAAA,EACtC,GATqD;AAWrD,SAAO;AAAA,IACN,GAAG;AAAA,IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gCAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAIJ;AAAA,YACtB,KAAK,IAAI;AAAA,YACT,KAAK,QAAQ;AAAA,YACb,MAAM;AAAA,YAAC;AAAA,UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;AAAA,QAC7C;AAAA,MACD,GAT+B;AAU/B,aAAOK,mBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;AAAA,IACxE;AAAA,EACD;AACD;AAxCS,OAAAH,sBAAA;AA0CT,SAASI,sBACR,OAC8B;AAE9B,MACCH,sCAAqC,UACrCA,kCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAcA,mCAAkC;AAC1D,IAAAC,qBAAoB,UAAU;AAAA,EAC/B;AAGA,SAAO,cAAc,MAAM;AAAA,IAC1B,mBAAyE,wBACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;AAAA,MACvE;AACA,aAAO,MAAM,MAAM,OAAO;AAAA,IAC3B,GAXyE;AAAA,IAazE,cAA0B,wBAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAIJ;AAAA,UACtB,KAAK,IAAI;AAAA,UACT,KAAK,QAAQ;AAAA,UACb,MAAM;AAAA,UAAC;AAAA,QACR;AACA,eAAO,MAAM,UAAU,UAAU;AAAA,MAClC;AAAA,IACD,GAT0B;AAAA,IAW1B,MAAM,SAAwD;AAC7D,aAAOK;AAAA,QACN;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MACN;AAAA,IACD;AAAA,EACD;AACD;AAnDS,OAAAC,uBAAA;AAqDT,IAAIC;AACJ,IAAI,OAAOC,yCAAU,UAAU;AAC9B,EAAAD,iBAAgBL,qBAAoBM,oCAAK;AAC1C,WAAW,OAAOA,yCAAU,YAAY;AACvC,EAAAD,iBAAgBD,sBAAqBE,oCAAK;AAC3C;AACA,IAAOC,mCAAQF;",
  "names": ["__name", "isEnglish", "value", "_a", "result", "char", "prefix", "i", "drainBody", "middleware_ensure_req_body_drained_default", "reduceError", "jsonError", "middleware_miniflare3_json_error_default", "__INTERNAL_WRANGLER_MIDDLEWARE__", "middleware_ensure_req_body_drained_default", "middleware_miniflare3_json_error_default", "middleware_insertion_facade_default", "__facade_middleware__", "__facade_register__", "__facade_invokeChain__", "__facade_invoke__", "__facade_middleware__", "__Facade_ScheduledController__", "___Facade_ScheduledController__", "wrapExportedHandler", "__INTERNAL_WRANGLER_MIDDLEWARE__", "__facade_register__", "__facade_invoke__", "wrapWorkerEntrypoint", "WRAPPED_ENTRY", "middleware_insertion_facade_default", "middleware_loader_entry_default"]
}
